{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import ngrams\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:20:04.683003900Z",
     "start_time": "2025-03-11T07:20:04.667367700Z"
    }
   },
   "id": "5e1d2aaf214edd8a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:20:16.647310500Z",
     "start_time": "2025-03-11T07:20:08.680326300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        id                                              title  \\\n0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n3  8600013  Robust offline trained neural network for TDOA...   \n4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n\n                                             keyword  \\\n0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n\n                                            abstract                 Class  \\\n0  To solve the problems of the data reliability ...  Human-generated text   \n1  To solve the simultaneous localization and map...  Human-generated text   \n2  In the future scenario of multiple wireless ne...  Human-generated text   \n3  Passive sound source localization (SSL) using ...  Human-generated text   \n4  We consider a two user Gaussian multiple acces...  Human-generated text   \n\n   Unnamed: 0.1  Unnamed: 0  index  \n0           NaN         NaN    NaN  \n1           NaN         NaN    NaN  \n2           NaN         NaN    NaN  \n3           NaN         NaN    NaN  \n4           NaN         NaN    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>keyword</th>\n      <th>abstract</th>\n      <th>Class</th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8600003</td>\n      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n      <td>To solve the problems of the data reliability ...</td>\n      <td>Human-generated text</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8600004</td>\n      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n      <td>To solve the simultaneous localization and map...</td>\n      <td>Human-generated text</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8600008</td>\n      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n      <td>In the future scenario of multiple wireless ne...</td>\n      <td>Human-generated text</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8600013</td>\n      <td>Robust offline trained neural network for TDOA...</td>\n      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n      <td>Passive sound source localization (SSL) using ...</td>\n      <td>Human-generated text</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8600014</td>\n      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n      <td>We consider a two user Gaussian multiple acces...</td>\n      <td>Human-generated text</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init = pd.read_excel('../data/dataset_1/ieee-init.xlsx')\n",
    "df_init['Class'] = 'Human-generated text'\n",
    "\n",
    "df_polish = pd.read_excel('../data/dataset_1/ieee-chatgpt-polish.xlsx')\n",
    "df_polish['Class'] = 'ChatGPT-polish text'\n",
    "\n",
    "df_generation = pd.read_excel('../data/dataset_1/ieee-chatgpt-generation.xlsx')\n",
    "df_generation['Class'] = 'ChatGPT-generated text'\n",
    "\n",
    "df_fusion = pd.read_excel('../data/dataset_1/ieee-chatgpt-fusion.xlsx')\n",
    "df_fusion['Class'] = 'Mixed text'\n",
    "\n",
    "df = pd.concat([df_init, df_generation, df_polish, df_fusion], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50699 entries, 0 to 50698\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       50699 non-null  int64 \n",
      " 1   title    50699 non-null  object\n",
      " 2   keyword  50699 non-null  object\n",
      " 3   Text     50699 non-null  object\n",
      " 4   Class    50699 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['index', 'Unnamed: 0', 'Unnamed: 0.1'])\n",
    "df = df.rename(columns={'abstract': 'Text'})\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:20:24.997066500Z",
     "start_time": "2025-03-11T07:20:24.919705800Z"
    }
   },
   "id": "729fb714b883729d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "50eec21a67e438db"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if (token.is_alpha and not token.is_stop and len(token) > 2)\n",
    "    ]\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:20:41.840097500Z",
     "start_time": "2025-03-11T07:20:40.373856800Z"
    }
   },
   "id": "1bedcc5402131532"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        id                                              title  \\\n0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n3  8600013  Robust offline trained neural network for TDOA...   \n4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n\n                                             keyword  \\\n0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n\n                                                Text                 Class  \\\n0  To solve the problems of the data reliability ...  Human-generated text   \n1  To solve the simultaneous localization and map...  Human-generated text   \n2  In the future scenario of multiple wireless ne...  Human-generated text   \n3  Passive sound source localization (SSL) using ...  Human-generated text   \n4  We consider a two user Gaussian multiple acces...  Human-generated text   \n\n                                              tokens  \n0  [solve, problem, data, reliability, nand, flas...  \n1  [solve, simultaneous, localization, mapping, s...  \n2  [future, scenario, multiple, wireless, network...  \n3  [passive, sound, source, localization, ssl, ti...  \n4  [consider, user, gaussian, multiple, access, c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>keyword</th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8600003</td>\n      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n      <td>To solve the problems of the data reliability ...</td>\n      <td>Human-generated text</td>\n      <td>[solve, problem, data, reliability, nand, flas...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8600004</td>\n      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n      <td>To solve the simultaneous localization and map...</td>\n      <td>Human-generated text</td>\n      <td>[solve, simultaneous, localization, mapping, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8600008</td>\n      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n      <td>In the future scenario of multiple wireless ne...</td>\n      <td>Human-generated text</td>\n      <td>[future, scenario, multiple, wireless, network...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8600013</td>\n      <td>Robust offline trained neural network for TDOA...</td>\n      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n      <td>Passive sound source localization (SSL) using ...</td>\n      <td>Human-generated text</td>\n      <td>[passive, sound, source, localization, ssl, ti...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8600014</td>\n      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n      <td>We consider a two user Gaussian multiple acces...</td>\n      <td>Human-generated text</td>\n      <td>[consider, user, gaussian, multiple, access, c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['Text'].apply(clean_text)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:38:58.066019Z",
     "start_time": "2025-03-11T07:20:43.992783300Z"
    }
   },
   "id": "185817c2f3b9f612"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def type_token_ratio(words):\n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "def calculate_entropy(words):\n",
    "    word_freq = Counter(words)\n",
    "    probabilities = np.array(list(word_freq.values())) / len(words)\n",
    "    return entropy(probabilities)\n",
    "\n",
    "def perplexity(words):\n",
    "    return np.exp(calculate_entropy(words))\n",
    "\n",
    "def sentence_paragraph_variability(text, words):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_lengths = [len(word_tokenize(sent)) for sent in sentences]\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    paragraph_lengths = [len(word_tokenize(para)) for para in paragraphs if para.strip()]\n",
    "    return np.std(sentence_lengths), np.std(paragraph_lengths)\n",
    "\n",
    "def ngram_distribution(words, n=2):\n",
    "    n_grams = list(ngrams(words, n))\n",
    "    return Counter(n_grams).most_common(5)\n",
    "\n",
    "def abstractness(words):\n",
    "    abstract_words = {\"concept\", \"idea\", \"theory\", \"model\", \"framework\", \"paradigm\"}\n",
    "    return len([word for word in words if word in abstract_words]) / len(words) if words else 0\n",
    "\n",
    "def repetitiveness(words):\n",
    "    word_freq = Counter(words)\n",
    "    return max(word_freq.values()) / len(words) if words else 0\n",
    "\n",
    "def syntactic_complexity(text):\n",
    "    doc = nlp(text)\n",
    "    complex_sentences = sum(1 for sent in doc.sents if sum(1 for token in sent if token.dep_ in ['advcl', 'ccomp', 'xcomp']) > 0)\n",
    "    return complex_sentences / len(list(doc.sents)) if doc.sents else 0\n",
    "\n",
    "def avg_word_sentence_length(words, text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    avg_word_len = np.mean([len(word) for word in words]) if words else 0\n",
    "    avg_sent_len = np.mean([len(word_tokenize(sent)) for sent in sentences]) if sentences else 0\n",
    "    return avg_word_len, avg_sent_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T07:40:48.203004800Z",
     "start_time": "2025-03-11T07:40:48.166017400Z"
    }
   },
   "id": "3a89de795c58cbcb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df['tokens'] = df['Text'].apply(clean_text)\n",
    "df['ttr'] = df['tokens'].apply(type_token_ratio)\n",
    "df['entropy'] = df['tokens'].apply(calculate_entropy)\n",
    "df['perplexity'] = df['tokens'].apply(perplexity)\n",
    "df['sentence_var'], df['paragraph_var'] = zip(*df.apply(\n",
    "    lambda row: sentence_paragraph_variability(row['Text'], row['tokens']), axis=1))\n",
    "df['abstractness'] = df['tokens'].apply(abstractness)\n",
    "df['repetitiveness'] = df['tokens'].apply(repetitiveness)\n",
    "df['syntactic_complexity'] = df['Text'].apply(syntactic_complexity)\n",
    "df['avg_word_length'], df['avg_sentence_length'] = zip(*df.apply(\n",
    "    lambda row: avg_word_sentence_length(row['tokens'], row['Text']), axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:19:04.587030900Z",
     "start_time": "2025-03-11T07:41:21.339611400Z"
    }
   },
   "id": "cf9d2e720aab5cab"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df.to_csv('../data/dataset_1/preprocessed_df_custom_features.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:19:07.422487300Z",
     "start_time": "2025-03-11T08:19:04.580171100Z"
    }
   },
   "id": "b89a8af5d78dc1b4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "        id                                              title  \\\n0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n3  8600013  Robust offline trained neural network for TDOA...   \n4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n\n                                             keyword  \\\n0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n\n                                                Text                 Class  \\\n0  To solve the problems of the data reliability ...  Human-generated text   \n1  To solve the simultaneous localization and map...  Human-generated text   \n2  In the future scenario of multiple wireless ne...  Human-generated text   \n3  Passive sound source localization (SSL) using ...  Human-generated text   \n4  We consider a two user Gaussian multiple acces...  Human-generated text   \n\n                                              tokens       ttr   entropy  \\\n0  [solve, problem, data, reliability, nand, flas...  0.714286  3.891327   \n1  [solve, simultaneous, localization, mapping, s...  0.710145  3.761766   \n2  [future, scenario, multiple, wireless, network...  0.760000  3.963848   \n3  [passive, sound, source, localization, ssl, ti...  0.728395  3.939887   \n4  [consider, user, gaussian, multiple, access, c...  0.720588  3.730491   \n\n   perplexity  sentence_var  paragraph_var  abstractness  repetitiveness  \\\n0   48.975853      8.015610            0.0      0.000000        0.051948   \n1   43.024356      7.303899            0.0      0.000000        0.086957   \n2   52.659546      7.605261            0.0      0.000000        0.040000   \n3   51.412767      5.314593            0.0      0.000000        0.074074   \n4   41.699563      4.611432            0.0      0.014706        0.073529   \n\n   syntactic_complexity  avg_word_length  avg_sentence_length  \n0              1.000000         6.974026            33.500000  \n1              0.857143         7.507246            22.714286  \n2              0.400000         7.320000            29.400000  \n3              0.285714         6.864198            21.571429  \n4              0.285714         7.205882            19.142857  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>keyword</th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>tokens</th>\n      <th>ttr</th>\n      <th>entropy</th>\n      <th>perplexity</th>\n      <th>sentence_var</th>\n      <th>paragraph_var</th>\n      <th>abstractness</th>\n      <th>repetitiveness</th>\n      <th>syntactic_complexity</th>\n      <th>avg_word_length</th>\n      <th>avg_sentence_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8600003</td>\n      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n      <td>To solve the problems of the data reliability ...</td>\n      <td>Human-generated text</td>\n      <td>[solve, problem, data, reliability, nand, flas...</td>\n      <td>0.714286</td>\n      <td>3.891327</td>\n      <td>48.975853</td>\n      <td>8.015610</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.051948</td>\n      <td>1.000000</td>\n      <td>6.974026</td>\n      <td>33.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8600004</td>\n      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n      <td>To solve the simultaneous localization and map...</td>\n      <td>Human-generated text</td>\n      <td>[solve, simultaneous, localization, mapping, s...</td>\n      <td>0.710145</td>\n      <td>3.761766</td>\n      <td>43.024356</td>\n      <td>7.303899</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.086957</td>\n      <td>0.857143</td>\n      <td>7.507246</td>\n      <td>22.714286</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8600008</td>\n      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n      <td>In the future scenario of multiple wireless ne...</td>\n      <td>Human-generated text</td>\n      <td>[future, scenario, multiple, wireless, network...</td>\n      <td>0.760000</td>\n      <td>3.963848</td>\n      <td>52.659546</td>\n      <td>7.605261</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.040000</td>\n      <td>0.400000</td>\n      <td>7.320000</td>\n      <td>29.400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8600013</td>\n      <td>Robust offline trained neural network for TDOA...</td>\n      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n      <td>Passive sound source localization (SSL) using ...</td>\n      <td>Human-generated text</td>\n      <td>[passive, sound, source, localization, ssl, ti...</td>\n      <td>0.728395</td>\n      <td>3.939887</td>\n      <td>51.412767</td>\n      <td>5.314593</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.074074</td>\n      <td>0.285714</td>\n      <td>6.864198</td>\n      <td>21.571429</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8600014</td>\n      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n      <td>We consider a two user Gaussian multiple acces...</td>\n      <td>Human-generated text</td>\n      <td>[consider, user, gaussian, multiple, access, c...</td>\n      <td>0.720588</td>\n      <td>3.730491</td>\n      <td>41.699563</td>\n      <td>4.611432</td>\n      <td>0.0</td>\n      <td>0.014706</td>\n      <td>0.073529</td>\n      <td>0.285714</td>\n      <td>7.205882</td>\n      <td>19.142857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:20:02.100444100Z",
     "start_time": "2025-03-11T08:20:02.000274800Z"
    }
   },
   "id": "d075cf0cbb387642"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fad63c1649a8638d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((35489, 16), (15210, 16))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.7, random_state=42, stratify=df['Class'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:20:27.717712Z",
     "start_time": "2025-03-11T08:20:27.608214100Z"
    }
   },
   "id": "f621c4ce451ba92c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cfefaf7aaf8dffce"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "feature_columns = ['ttr', 'entropy', 'perplexity', 'sentence_var', 'paragraph_var', 'abstractness', 'repetitiveness', 'syntactic_complexity', 'avg_word_length', 'avg_sentence_length']\n",
    "X_train, X_test = df_train[feature_columns], df_test[feature_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:20:32.914744500Z",
     "start_time": "2025-03-11T08:20:32.882010Z"
    }
   },
   "id": "420a88990fb89be3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasy: ['ChatGPT-generated text' 'ChatGPT-polish text' 'Human-generated text'\n",
      " 'Mixed text']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['Class'])\n",
    "y_test = label_encoder.transform(df_test['Class'])\n",
    "\n",
    "joblib.dump(label_encoder, '../models/dataset_1/label_encoder.joblib')\n",
    "print(\"Klasy:\", label_encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:20:42.732365900Z",
     "start_time": "2025-03-11T08:20:42.659447100Z"
    }
   },
   "id": "1df90106b2581c48"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b95bca64f1878a0e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: LR\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.63298478        nan 0.63335107 0.63475999 0.63295661        nan\n",
      " 0.63335109 0.63687358 0.63318203        nan 0.63323838 0.63470376]\n",
      "  warnings.warn(\n",
      "C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla LR: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Najlepsza dokładność (CV) dla LR: 0.6369\n",
      "Model LR zapisany jako: ../models/dataset_1\\LR_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weran\\PycharmProjects\\magisterka\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'LR',\n",
    "    'estimator': LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "    'param_grid': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga', 'lbfgs']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:23:35.962356700Z",
     "start_time": "2025-03-11T08:21:23.953919700Z"
    }
   },
   "id": "13cdc7c7c7bf79de"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: DT\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Najlepsze parametry dla DT: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Najlepsza dokładność (CV) dla DT: 0.6434\n",
      "Model DT zapisany jako: ../models/dataset_1\\DT_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6388\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'DT',\n",
    "    'estimator': DecisionTreeClassifier(random_state=42),\n",
    "    'param_grid': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T08:32:50.899162700Z",
     "start_time": "2025-03-11T08:31:41.036884900Z"
    }
   },
   "id": "bf9f9074640528d3"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: RF\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Najlepsze parametry dla RF: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Najlepsza dokładność (CV) dla RF: 0.6669\n",
      "Model RF zapisany jako: ../models/dataset_1\\RF_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6594\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'RF',\n",
    "    'estimator': RandomForestClassifier(random_state=42),\n",
    "    'param_grid': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T09:00:16.479329400Z",
     "start_time": "2025-03-11T08:33:14.122286200Z"
    }
   },
   "id": "bcaf83b9d85bcc8f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: NB\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Najlepsze parametry dla NB: {'var_smoothing': 1e-07}\n",
      "Najlepsza dokładność (CV) dla NB: 0.4409\n",
      "Model NB zapisany jako: ../models/dataset_1\\NB_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.4385\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'NB',\n",
    "    'estimator': GaussianNB(),\n",
    "    'param_grid': {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T09:01:02.420471500Z",
     "start_time": "2025-03-11T09:01:01.970850500Z"
    }
   },
   "id": "3a68ca1cad615456"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: KNN\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Najlepsze parametry dla KNN: {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'distance'}\n",
      "Najlepsza dokładność (CV) dla KNN: 0.6322\n",
      "Model KNN zapisany jako: ../models/dataset_1\\KNN_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6218\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'KNN',\n",
    "    'estimator': KNeighborsClassifier(),\n",
    "    'param_grid': {\n",
    "        'n_neighbors': [5, 10, 20],\n",
    "        'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T09:01:20.316643900Z",
     "start_time": "2025-03-11T09:01:08.160773400Z"
    }
   },
   "id": "14ee621b1eeb109b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: SVM\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Najlepsze parametry dla SVM: {'C': 10, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Najlepsza dokładność (CV) dla SVM: 0.6510\n",
      "Model SVM zapisany jako: ../models/dataset_1\\SVM_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6428\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'SVM',\n",
    "    'estimator': SVC(random_state=42),\n",
    "    'param_grid': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T13:57:13.018802800Z",
     "start_time": "2025-03-11T11:48:23.811156900Z"
    }
   },
   "id": "ba7f1ad5bc5a59d3"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: MLP\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Najlepsze parametry dla MLP: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Najlepsza dokładność (CV) dla MLP: 0.6604\n",
      "Model MLP zapisany jako: ../models/dataset_1\\MLP_best_model_custom_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6538\n"
     ]
    }
   ],
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'MLP',\n",
    "        'estimator': MLPClassifier(random_state=42, early_stopping=True, n_iter_no_change=5),\n",
    "        'param_grid': {\n",
    "            'hidden_layer_sizes': [(100,), (50,50), (100,50,25)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate': ['constant', 'adaptive', 'invscaling']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_custom_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:47:37.765016700Z",
     "start_time": "2025-03-11T10:05:14.869921800Z"
    }
   },
   "id": "a6f9bde7fe43a754"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3d4eeccce897b3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
