{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T10:59:19.321860Z",
     "start_time": "2025-03-11T10:59:16.626675Z"
    }
   },
   "id": "5e1d2aaf214edd8a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T10:59:25.354010Z",
     "start_time": "2025-03-11T10:59:19.991852Z"
    }
   },
   "source": [
    "df_init = pd.read_excel('../data/dataset_1/ieee-init.xlsx')\n",
    "df_init['Class'] = 'Human-generated text'\n",
    "\n",
    "df_polish = pd.read_excel('../data/dataset_1/ieee-chatgpt-polish.xlsx')\n",
    "df_polish['Class'] = 'ChatGPT-polish text'\n",
    "\n",
    "df_generation = pd.read_excel('../data/dataset_1/ieee-chatgpt-generation.xlsx')\n",
    "df_generation['Class'] = 'ChatGPT-generated text'\n",
    "\n",
    "df_fusion = pd.read_excel('../data/dataset_1/ieee-chatgpt-fusion.xlsx')\n",
    "df_fusion['Class'] = 'Mixed text'\n",
    "\n",
    "df = pd.concat([df_init, df_generation, df_polish, df_fusion], ignore_index=True)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id                                              title  \\\n",
       "0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n",
       "1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n",
       "2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n",
       "3  8600013  Robust offline trained neural network for TDOA...   \n",
       "4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n",
       "\n",
       "                                             keyword  \\\n",
       "0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n",
       "1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n",
       "2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n",
       "3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n",
       "4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n",
       "\n",
       "                                            abstract                 Class  \\\n",
       "0  To solve the problems of the data reliability ...  Human-generated text   \n",
       "1  To solve the simultaneous localization and map...  Human-generated text   \n",
       "2  In the future scenario of multiple wireless ne...  Human-generated text   \n",
       "3  Passive sound source localization (SSL) using ...  Human-generated text   \n",
       "4  We consider a two user Gaussian multiple acces...  Human-generated text   \n",
       "\n",
       "   Unnamed: 0.1  Unnamed: 0  index  \n",
       "0           NaN         NaN    NaN  \n",
       "1           NaN         NaN    NaN  \n",
       "2           NaN         NaN    NaN  \n",
       "3           NaN         NaN    NaN  \n",
       "4           NaN         NaN    NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Class</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8600003</td>\n",
       "      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n",
       "      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n",
       "      <td>To solve the problems of the data reliability ...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8600004</td>\n",
       "      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n",
       "      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n",
       "      <td>To solve the simultaneous localization and map...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8600008</td>\n",
       "      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n",
       "      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n",
       "      <td>In the future scenario of multiple wireless ne...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8600013</td>\n",
       "      <td>Robust offline trained neural network for TDOA...</td>\n",
       "      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n",
       "      <td>Passive sound source localization (SSL) using ...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8600014</td>\n",
       "      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n",
       "      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n",
       "      <td>We consider a two user Gaussian multiple acces...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=['index', 'Unnamed: 0', 'Unnamed: 0.1'])\n",
    "df = df.rename(columns={'abstract': 'Text'})\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T10:59:29.514697Z",
     "start_time": "2025-03-11T10:59:29.466564Z"
    }
   },
   "id": "729fb714b883729d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50699 entries, 0 to 50698\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       50699 non-null  int64 \n",
      " 1   title    50699 non-null  object\n",
      " 2   keyword  50699 non-null  object\n",
      " 3   Text     50699 non-null  object\n",
      " 4   Class    50699 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "50eec21a67e438db"
  },
  {
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.text for token in doc if token.is_alpha or token.is_digit]\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:00:24.938039Z",
     "start_time": "2025-03-11T11:00:24.303017Z"
    }
   },
   "id": "1bedcc5402131532",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "df['tokens'] = df['Text'].apply(clean_text)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:18:23.681771Z",
     "start_time": "2025-03-11T11:00:31.636298Z"
    }
   },
   "id": "185817c2f3b9f612",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id                                              title  \\\n",
       "0  8600003  An Improved Variable-Node-Based BP Decoding Al...   \n",
       "1  8600004  Mobile Robot Location Algorithm Based on Impro...   \n",
       "2  8600008  Vertical Handoff Decision Algorithm for Hetero...   \n",
       "3  8600013  Robust offline trained neural network for TDOA...   \n",
       "4  8600014  Gaussian MAC with Feedback and Strictly Causal...   \n",
       "\n",
       "                                             keyword  \\\n",
       "0  \"Flash memories\",\"Reliability\",\"Decoding\",\"Par...   \n",
       "1  \"Sociology\",\"Statistics\",\"Simultaneous localiz...   \n",
       "2  \"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...   \n",
       "3  \"Microphones\",\"Artificial neural networks\",\"Po...   \n",
       "4  \"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...   \n",
       "\n",
       "                                                Text                 Class  \\\n",
       "0  To solve the problems of the data reliability ...  Human-generated text   \n",
       "1  To solve the simultaneous localization and map...  Human-generated text   \n",
       "2  In the future scenario of multiple wireless ne...  Human-generated text   \n",
       "3  Passive sound source localization (SSL) using ...  Human-generated text   \n",
       "4  We consider a two user Gaussian multiple acces...  Human-generated text   \n",
       "\n",
       "                                              tokens  \n",
       "0  [to, solve, the, problems, of, the, data, reli...  \n",
       "1  [to, solve, the, simultaneous, localization, a...  \n",
       "2  [in, the, future, scenario, of, multiple, wire...  \n",
       "3  [passive, sound, source, localization, ssl, us...  \n",
       "4  [we, consider, a, two, user, gaussian, multipl...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>keyword</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8600003</td>\n",
       "      <td>An Improved Variable-Node-Based BP Decoding Al...</td>\n",
       "      <td>\"Flash memories\",\"Reliability\",\"Decoding\",\"Par...</td>\n",
       "      <td>To solve the problems of the data reliability ...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>[to, solve, the, problems, of, the, data, reli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8600004</td>\n",
       "      <td>Mobile Robot Location Algorithm Based on Impro...</td>\n",
       "      <td>\"Sociology\",\"Statistics\",\"Simultaneous localiz...</td>\n",
       "      <td>To solve the simultaneous localization and map...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>[to, solve, the, simultaneous, localization, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8600008</td>\n",
       "      <td>Vertical Handoff Decision Algorithm for Hetero...</td>\n",
       "      <td>\"Entropy\",\"Handover\",\"Wireless networks\",\"Deci...</td>\n",
       "      <td>In the future scenario of multiple wireless ne...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>[in, the, future, scenario, of, multiple, wire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8600013</td>\n",
       "      <td>Robust offline trained neural network for TDOA...</td>\n",
       "      <td>\"Microphones\",\"Artificial neural networks\",\"Po...</td>\n",
       "      <td>Passive sound source localization (SSL) using ...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>[passive, sound, source, localization, ssl, us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8600014</td>\n",
       "      <td>Gaussian MAC with Feedback and Strictly Causal...</td>\n",
       "      <td>\"Encoding\",\"Transmitters\",\"Decoding\",\"Indexes\"...</td>\n",
       "      <td>We consider a two user Gaussian multiple acces...</td>\n",
       "      <td>Human-generated text</td>\n",
       "      <td>[we, consider, a, two, user, gaussian, multipl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv('../data/dataset_1/preprocessed_df_doc2vec.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:18:34.508847Z",
     "start_time": "2025-03-11T11:18:29.617953Z"
    }
   },
   "id": "bd1430191f853af3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fad63c1649a8638d"
  },
  {
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test_split(df, train_size=0.7, random_state=42, stratify=df['Class'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:19:12.290790Z",
     "start_time": "2025-03-11T11:19:12.237483Z"
    }
   },
   "id": "f621c4ce451ba92c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35489, 6), (15210, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cfefaf7aaf8dffce"
  },
  {
   "cell_type": "code",
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Callback do śledzenia treningu\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Start epoki {self.epoch}\")\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"Koniec epoki {self.epoch}\")\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "epoch_logger = EpochLogger()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:19:16.095861Z",
     "start_time": "2025-03-11T11:19:16.091542Z"
    }
   },
   "id": "c54ea625fcaba12e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df_train['tokens'])]\n",
    "\n",
    "doc2vec_model = Doc2Vec(vector_size=200, window=10, epochs=200, min_count=1, dm=1, workers=4)\n",
    "doc2vec_model.build_vocab(documents)\n",
    "doc2vec_model.train(documents, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs, callbacks=[epoch_logger])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:33:37.500928Z",
     "start_time": "2025-03-11T11:19:22.919233Z"
    }
   },
   "id": "d6e084e374c84064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoki 0\n",
      "Koniec epoki 0\n",
      "Start epoki 1\n",
      "Koniec epoki 1\n",
      "Start epoki 2\n",
      "Koniec epoki 2\n",
      "Start epoki 3\n",
      "Koniec epoki 3\n",
      "Start epoki 4\n",
      "Koniec epoki 4\n",
      "Start epoki 5\n",
      "Koniec epoki 5\n",
      "Start epoki 6\n",
      "Koniec epoki 6\n",
      "Start epoki 7\n",
      "Koniec epoki 7\n",
      "Start epoki 8\n",
      "Koniec epoki 8\n",
      "Start epoki 9\n",
      "Koniec epoki 9\n",
      "Start epoki 10\n",
      "Koniec epoki 10\n",
      "Start epoki 11\n",
      "Koniec epoki 11\n",
      "Start epoki 12\n",
      "Koniec epoki 12\n",
      "Start epoki 13\n",
      "Koniec epoki 13\n",
      "Start epoki 14\n",
      "Koniec epoki 14\n",
      "Start epoki 15\n",
      "Koniec epoki 15\n",
      "Start epoki 16\n",
      "Koniec epoki 16\n",
      "Start epoki 17\n",
      "Koniec epoki 17\n",
      "Start epoki 18\n",
      "Koniec epoki 18\n",
      "Start epoki 19\n",
      "Koniec epoki 19\n",
      "Start epoki 20\n",
      "Koniec epoki 20\n",
      "Start epoki 21\n",
      "Koniec epoki 21\n",
      "Start epoki 22\n",
      "Koniec epoki 22\n",
      "Start epoki 23\n",
      "Koniec epoki 23\n",
      "Start epoki 24\n",
      "Koniec epoki 24\n",
      "Start epoki 25\n",
      "Koniec epoki 25\n",
      "Start epoki 26\n",
      "Koniec epoki 26\n",
      "Start epoki 27\n",
      "Koniec epoki 27\n",
      "Start epoki 28\n",
      "Koniec epoki 28\n",
      "Start epoki 29\n",
      "Koniec epoki 29\n",
      "Start epoki 30\n",
      "Koniec epoki 30\n",
      "Start epoki 31\n",
      "Koniec epoki 31\n",
      "Start epoki 32\n",
      "Koniec epoki 32\n",
      "Start epoki 33\n",
      "Koniec epoki 33\n",
      "Start epoki 34\n",
      "Koniec epoki 34\n",
      "Start epoki 35\n",
      "Koniec epoki 35\n",
      "Start epoki 36\n",
      "Koniec epoki 36\n",
      "Start epoki 37\n",
      "Koniec epoki 37\n",
      "Start epoki 38\n",
      "Koniec epoki 38\n",
      "Start epoki 39\n",
      "Koniec epoki 39\n",
      "Start epoki 40\n",
      "Koniec epoki 40\n",
      "Start epoki 41\n",
      "Koniec epoki 41\n",
      "Start epoki 42\n",
      "Koniec epoki 42\n",
      "Start epoki 43\n",
      "Koniec epoki 43\n",
      "Start epoki 44\n",
      "Koniec epoki 44\n",
      "Start epoki 45\n",
      "Koniec epoki 45\n",
      "Start epoki 46\n",
      "Koniec epoki 46\n",
      "Start epoki 47\n",
      "Koniec epoki 47\n",
      "Start epoki 48\n",
      "Koniec epoki 48\n",
      "Start epoki 49\n",
      "Koniec epoki 49\n",
      "Start epoki 50\n",
      "Koniec epoki 50\n",
      "Start epoki 51\n",
      "Koniec epoki 51\n",
      "Start epoki 52\n",
      "Koniec epoki 52\n",
      "Start epoki 53\n",
      "Koniec epoki 53\n",
      "Start epoki 54\n",
      "Koniec epoki 54\n",
      "Start epoki 55\n",
      "Koniec epoki 55\n",
      "Start epoki 56\n",
      "Koniec epoki 56\n",
      "Start epoki 57\n",
      "Koniec epoki 57\n",
      "Start epoki 58\n",
      "Koniec epoki 58\n",
      "Start epoki 59\n",
      "Koniec epoki 59\n",
      "Start epoki 60\n",
      "Koniec epoki 60\n",
      "Start epoki 61\n",
      "Koniec epoki 61\n",
      "Start epoki 62\n",
      "Koniec epoki 62\n",
      "Start epoki 63\n",
      "Koniec epoki 63\n",
      "Start epoki 64\n",
      "Koniec epoki 64\n",
      "Start epoki 65\n",
      "Koniec epoki 65\n",
      "Start epoki 66\n",
      "Koniec epoki 66\n",
      "Start epoki 67\n",
      "Koniec epoki 67\n",
      "Start epoki 68\n",
      "Koniec epoki 68\n",
      "Start epoki 69\n",
      "Koniec epoki 69\n",
      "Start epoki 70\n",
      "Koniec epoki 70\n",
      "Start epoki 71\n",
      "Koniec epoki 71\n",
      "Start epoki 72\n",
      "Koniec epoki 72\n",
      "Start epoki 73\n",
      "Koniec epoki 73\n",
      "Start epoki 74\n",
      "Koniec epoki 74\n",
      "Start epoki 75\n",
      "Koniec epoki 75\n",
      "Start epoki 76\n",
      "Koniec epoki 76\n",
      "Start epoki 77\n",
      "Koniec epoki 77\n",
      "Start epoki 78\n",
      "Koniec epoki 78\n",
      "Start epoki 79\n",
      "Koniec epoki 79\n",
      "Start epoki 80\n",
      "Koniec epoki 80\n",
      "Start epoki 81\n",
      "Koniec epoki 81\n",
      "Start epoki 82\n",
      "Koniec epoki 82\n",
      "Start epoki 83\n",
      "Koniec epoki 83\n",
      "Start epoki 84\n",
      "Koniec epoki 84\n",
      "Start epoki 85\n",
      "Koniec epoki 85\n",
      "Start epoki 86\n",
      "Koniec epoki 86\n",
      "Start epoki 87\n",
      "Koniec epoki 87\n",
      "Start epoki 88\n",
      "Koniec epoki 88\n",
      "Start epoki 89\n",
      "Koniec epoki 89\n",
      "Start epoki 90\n",
      "Koniec epoki 90\n",
      "Start epoki 91\n",
      "Koniec epoki 91\n",
      "Start epoki 92\n",
      "Koniec epoki 92\n",
      "Start epoki 93\n",
      "Koniec epoki 93\n",
      "Start epoki 94\n",
      "Koniec epoki 94\n",
      "Start epoki 95\n",
      "Koniec epoki 95\n",
      "Start epoki 96\n",
      "Koniec epoki 96\n",
      "Start epoki 97\n",
      "Koniec epoki 97\n",
      "Start epoki 98\n",
      "Koniec epoki 98\n",
      "Start epoki 99\n",
      "Koniec epoki 99\n",
      "Start epoki 100\n",
      "Koniec epoki 100\n",
      "Start epoki 101\n",
      "Koniec epoki 101\n",
      "Start epoki 102\n",
      "Koniec epoki 102\n",
      "Start epoki 103\n",
      "Koniec epoki 103\n",
      "Start epoki 104\n",
      "Koniec epoki 104\n",
      "Start epoki 105\n",
      "Koniec epoki 105\n",
      "Start epoki 106\n",
      "Koniec epoki 106\n",
      "Start epoki 107\n",
      "Koniec epoki 107\n",
      "Start epoki 108\n",
      "Koniec epoki 108\n",
      "Start epoki 109\n",
      "Koniec epoki 109\n",
      "Start epoki 110\n",
      "Koniec epoki 110\n",
      "Start epoki 111\n",
      "Koniec epoki 111\n",
      "Start epoki 112\n",
      "Koniec epoki 112\n",
      "Start epoki 113\n",
      "Koniec epoki 113\n",
      "Start epoki 114\n",
      "Koniec epoki 114\n",
      "Start epoki 115\n",
      "Koniec epoki 115\n",
      "Start epoki 116\n",
      "Koniec epoki 116\n",
      "Start epoki 117\n",
      "Koniec epoki 117\n",
      "Start epoki 118\n",
      "Koniec epoki 118\n",
      "Start epoki 119\n",
      "Koniec epoki 119\n",
      "Start epoki 120\n",
      "Koniec epoki 120\n",
      "Start epoki 121\n",
      "Koniec epoki 121\n",
      "Start epoki 122\n",
      "Koniec epoki 122\n",
      "Start epoki 123\n",
      "Koniec epoki 123\n",
      "Start epoki 124\n",
      "Koniec epoki 124\n",
      "Start epoki 125\n",
      "Koniec epoki 125\n",
      "Start epoki 126\n",
      "Koniec epoki 126\n",
      "Start epoki 127\n",
      "Koniec epoki 127\n",
      "Start epoki 128\n",
      "Koniec epoki 128\n",
      "Start epoki 129\n",
      "Koniec epoki 129\n",
      "Start epoki 130\n",
      "Koniec epoki 130\n",
      "Start epoki 131\n",
      "Koniec epoki 131\n",
      "Start epoki 132\n",
      "Koniec epoki 132\n",
      "Start epoki 133\n",
      "Koniec epoki 133\n",
      "Start epoki 134\n",
      "Koniec epoki 134\n",
      "Start epoki 135\n",
      "Koniec epoki 135\n",
      "Start epoki 136\n",
      "Koniec epoki 136\n",
      "Start epoki 137\n",
      "Koniec epoki 137\n",
      "Start epoki 138\n",
      "Koniec epoki 138\n",
      "Start epoki 139\n",
      "Koniec epoki 139\n",
      "Start epoki 140\n",
      "Koniec epoki 140\n",
      "Start epoki 141\n",
      "Koniec epoki 141\n",
      "Start epoki 142\n",
      "Koniec epoki 142\n",
      "Start epoki 143\n",
      "Koniec epoki 143\n",
      "Start epoki 144\n",
      "Koniec epoki 144\n",
      "Start epoki 145\n",
      "Koniec epoki 145\n",
      "Start epoki 146\n",
      "Koniec epoki 146\n",
      "Start epoki 147\n",
      "Koniec epoki 147\n",
      "Start epoki 148\n",
      "Koniec epoki 148\n",
      "Start epoki 149\n",
      "Koniec epoki 149\n",
      "Start epoki 150\n",
      "Koniec epoki 150\n",
      "Start epoki 151\n",
      "Koniec epoki 151\n",
      "Start epoki 152\n",
      "Koniec epoki 152\n",
      "Start epoki 153\n",
      "Koniec epoki 153\n",
      "Start epoki 154\n",
      "Koniec epoki 154\n",
      "Start epoki 155\n",
      "Koniec epoki 155\n",
      "Start epoki 156\n",
      "Koniec epoki 156\n",
      "Start epoki 157\n",
      "Koniec epoki 157\n",
      "Start epoki 158\n",
      "Koniec epoki 158\n",
      "Start epoki 159\n",
      "Koniec epoki 159\n",
      "Start epoki 160\n",
      "Koniec epoki 160\n",
      "Start epoki 161\n",
      "Koniec epoki 161\n",
      "Start epoki 162\n",
      "Koniec epoki 162\n",
      "Start epoki 163\n",
      "Koniec epoki 163\n",
      "Start epoki 164\n",
      "Koniec epoki 164\n",
      "Start epoki 165\n",
      "Koniec epoki 165\n",
      "Start epoki 166\n",
      "Koniec epoki 166\n",
      "Start epoki 167\n",
      "Koniec epoki 167\n",
      "Start epoki 168\n",
      "Koniec epoki 168\n",
      "Start epoki 169\n",
      "Koniec epoki 169\n",
      "Start epoki 170\n",
      "Koniec epoki 170\n",
      "Start epoki 171\n",
      "Koniec epoki 171\n",
      "Start epoki 172\n",
      "Koniec epoki 172\n",
      "Start epoki 173\n",
      "Koniec epoki 173\n",
      "Start epoki 174\n",
      "Koniec epoki 174\n",
      "Start epoki 175\n",
      "Koniec epoki 175\n",
      "Start epoki 176\n",
      "Koniec epoki 176\n",
      "Start epoki 177\n",
      "Koniec epoki 177\n",
      "Start epoki 178\n",
      "Koniec epoki 178\n",
      "Start epoki 179\n",
      "Koniec epoki 179\n",
      "Start epoki 180\n",
      "Koniec epoki 180\n",
      "Start epoki 181\n",
      "Koniec epoki 181\n",
      "Start epoki 182\n",
      "Koniec epoki 182\n",
      "Start epoki 183\n",
      "Koniec epoki 183\n",
      "Start epoki 184\n",
      "Koniec epoki 184\n",
      "Start epoki 185\n",
      "Koniec epoki 185\n",
      "Start epoki 186\n",
      "Koniec epoki 186\n",
      "Start epoki 187\n",
      "Koniec epoki 187\n",
      "Start epoki 188\n",
      "Koniec epoki 188\n",
      "Start epoki 189\n",
      "Koniec epoki 189\n",
      "Start epoki 190\n",
      "Koniec epoki 190\n",
      "Start epoki 191\n",
      "Koniec epoki 191\n",
      "Start epoki 192\n",
      "Koniec epoki 192\n",
      "Start epoki 193\n",
      "Koniec epoki 193\n",
      "Start epoki 194\n",
      "Koniec epoki 194\n",
      "Start epoki 195\n",
      "Koniec epoki 195\n",
      "Start epoki 196\n",
      "Koniec epoki 196\n",
      "Start epoki 197\n",
      "Koniec epoki 197\n",
      "Start epoki 198\n",
      "Koniec epoki 198\n",
      "Start epoki 199\n",
      "Koniec epoki 199\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "doc2vec_model_path = '../models/dataset_1/doc2vec_model_ds1.model'\n",
    "doc2vec_model.save(doc2vec_model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:33:37.633818Z",
     "start_time": "2025-03-11T11:33:37.526495Z"
    }
   },
   "id": "f6470f1fe6a2b9d5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef4940473861985d"
  },
  {
   "cell_type": "code",
   "source": [
    "def get_doc_vector(model, tokens):\n",
    "    return model.infer_vector(tokens)\n",
    "\n",
    "def extract_features(df_, model):\n",
    "    features = df_['tokens'].apply(lambda tokens: get_doc_vector(model, tokens))\n",
    "    X = np.vstack(features.values)\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T11:37:05.009132Z",
     "start_time": "2025-03-11T11:37:05.005590Z"
    }
   },
   "id": "cbb63a7ee7a0a8da",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = extract_features(df_train, doc2vec_model)\n",
    "X_test = extract_features(df_test, doc2vec_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:13:50.056488Z",
     "start_time": "2025-03-11T11:37:17.391427Z"
    }
   },
   "id": "b2a96e0a1e17dcad",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['Class'])\n",
    "y_test = label_encoder.transform(df_test['Class'])\n",
    "\n",
    "joblib.dump(label_encoder, '../models/dataset_1/label_encoder_d2v.joblib')\n",
    "print(\"Klasy:\", label_encoder.classes_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:13:50.096317Z",
     "start_time": "2025-03-11T12:13:50.081569Z"
    }
   },
   "id": "1df90106b2581c48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasy: ['ChatGPT-generated text' 'ChatGPT-polish text' 'Human-generated text'\n",
      " 'Mixed text']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b95bca64f1878a0e"
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'LR',\n",
    "    'estimator': LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42),\n",
    "    'param_grid': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga', 'lbfgs']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:20:45.390953Z",
     "start_time": "2025-03-11T12:14:04.197775Z"
    }
   },
   "id": "13cdc7c7c7bf79de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: LR\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.75815027        nan 0.7578403  0.75775581 0.75800937        nan\n",
      " 0.75792483 0.75798122 0.75786847        nan 0.75789666 0.75781217]\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla LR: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Najlepsza dokładność (CV) dla LR: 0.7582\n",
      "Model LR zapisany jako: ../models/dataset_1/LR_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.7491\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'DT',\n",
    "    'estimator': DecisionTreeClassifier(random_state=42),\n",
    "    'param_grid': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:55:11.871070Z",
     "start_time": "2025-03-11T12:28:20.602612Z"
    }
   },
   "id": "bf9f9074640528d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: DT\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Najlepsze parametry dla DT: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Najlepsza dokładność (CV) dla DT: 0.4506\n",
      "Model DT zapisany jako: ../models/dataset_1/DT_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.4426\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'RF',\n",
    "    'estimator': RandomForestClassifier(random_state=42),\n",
    "    'param_grid': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T15:17:11.444476Z",
     "start_time": "2025-03-11T12:56:49.778282Z"
    }
   },
   "id": "bcaf83b9d85bcc8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: RF\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   6.3s\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=   5.8s\n",
      "[CV] END .metric=minkowski, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   6.0s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   6.1s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time= 1.0min\n",
      "[CV] END ..metric=manhattan, n_neighbors=20, weights=uniform; total time=  47.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  20.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  18.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  18.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  17.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  15.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  19.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  22.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  20.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  16.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  28.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  29.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  31.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  33.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  23.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  21.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  21.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  32.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  29.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  25.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  24.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.3min\n",
      "[CV] END ................................var_smoothing=1e-09; total time=   0.4s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   6.4s\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=   5.8s\n",
      "[CV] END .metric=minkowski, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   6.6s\n",
      "[CV] END ..metric=euclidean, n_neighbors=20, weights=uniform; total time=   6.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=20, weights=uniform; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  21.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  18.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  17.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  13.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  13.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  17.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  16.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  15.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  19.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  20.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  22.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  16.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  28.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  32.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  31.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  24.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  21.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  21.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  31.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  29.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  30.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  25.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  25.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  24.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.9min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 2.1min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=   6.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=20, weights=uniform; total time=   5.9s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   6.6s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   6.6s\n",
      "[CV] END .metric=euclidean, n_neighbors=20, weights=distance; total time=   6.1s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time= 1.1min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time= 1.0min\n",
      "[CV] END .metric=manhattan, n_neighbors=20, weights=distance; total time=  47.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  20.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  20.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  18.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  15.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  17.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  17.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  16.4s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  19.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  19.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  23.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  16.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  32.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  31.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  22.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  21.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  21.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  31.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  29.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  29.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  24.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  27.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  25.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  24.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  41.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 3.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=   6.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=20, weights=uniform; total time=   5.9s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   6.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   6.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=20, weights=distance; total time=   5.9s\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=20, weights=uniform; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  19.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  18.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  17.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  16.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  15.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  19.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  23.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  16.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  28.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  32.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  32.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  22.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  22.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  21.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  24.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  30.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  27.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  29.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  27.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  25.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  41.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 3.0min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   6.6s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   6.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   8.4s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.5min\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   6.4s\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=   5.8s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   6.7s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   6.6s\n",
      "[CV] END .metric=euclidean, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time= 1.1min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time= 1.0min\n",
      "[CV] END .metric=manhattan, n_neighbors=20, weights=distance; total time=  47.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  20.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  18.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  19.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  22.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  20.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  16.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  31.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  33.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  26.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  25.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  23.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  21.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  21.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  32.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  29.6s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  30.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  26.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  29.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  21.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  41.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 3.0min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.9min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ................................var_smoothing=1e-09; total time=   0.3s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   6.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=   5.8s\n",
      "[CV] END .metric=minkowski, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   6.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=20, weights=uniform; total time=   6.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time= 1.0min\n",
      "[CV] END .metric=manhattan, n_neighbors=20, weights=distance; total time=  47.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  20.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  20.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  18.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  17.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  16.4s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  16.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  19.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  23.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  16.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  32.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  31.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  24.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  24.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  20.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  31.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  29.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  29.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  25.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  26.6s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  25.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  24.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  43.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.1min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 3.2min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END ................................var_smoothing=1e-09; total time=   0.3s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.2s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   6.3s\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=   5.8s\n",
      "[CV] END ..metric=minkowski, n_neighbors=20, weights=uniform; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   6.0s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   6.1s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time= 1.0min\n",
      "[CV] END .metric=manhattan, n_neighbors=20, weights=distance; total time=  47.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  20.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  18.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  18.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  15.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  15.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  20.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  22.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  21.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  16.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  28.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  32.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  32.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  28.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  24.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  25.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  22.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  22.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  21.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  21.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  20.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  24.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  30.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  29.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  26.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  24.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  25.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.2min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   6.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   7.6s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.8min\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.3s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   6.4s\n",
      "[CV] END ..metric=minkowski, n_neighbors=20, weights=uniform; total time=   5.9s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   6.6s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   6.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=20, weights=uniform; total time=   6.7s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time= 1.1min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  20.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  18.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  13.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  16.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  15.4s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  23.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  18.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  16.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  31.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  32.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  25.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  22.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  22.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  23.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  20.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  31.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  29.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  26.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  30.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  26.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  25.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  22.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  41.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  43.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.2min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ................................var_smoothing=1e-09; total time=   0.4s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.2s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   6.4s\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=   5.8s\n",
      "[CV] END .metric=minkowski, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   6.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=20, weights=uniform; total time=   6.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time= 1.1min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time= 1.0min\n",
      "[CV] END .metric=manhattan, n_neighbors=20, weights=distance; total time=  47.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  20.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  17.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  17.6s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  16.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  15.4s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  20.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  19.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  23.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  16.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  28.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  29.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  32.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  32.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  25.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  25.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=  12.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=  12.4s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=  12.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=  12.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  23.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  22.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  21.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  32.7s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  28.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  29.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  29.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  27.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  25.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  26.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  18.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.2min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   6.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   7.5s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 2.1min\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   6.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   7.9s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.3min\n",
      "[CV] END ................................var_smoothing=1e-08; total time=   0.3s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   6.4s\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=   5.8s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   6.8s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   6.6s\n",
      "[CV] END .metric=euclidean, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=20, weights=uniform; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  20.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  20.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  18.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  17.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  13.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  12.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=15; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  16.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2; total time=  15.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  19.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  23.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  18.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  16.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  16.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=15; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=15; total time=  32.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2; total time=  32.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  24.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  24.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=  12.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  22.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  23.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  22.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  21.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  24.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  30.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  26.6s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  29.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  27.1s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  27.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  25.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  25.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=  45.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=  49.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 3.0min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   5.9s\n",
      "[CV] END ..metric=minkowski, n_neighbors=20, weights=uniform; total time=   6.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   6.6s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   6.1s\n",
      "[CV] END .metric=euclidean, n_neighbors=20, weights=distance; total time=   5.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time= 1.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=20, weights=uniform; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  20.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  19.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  18.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  17.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=15; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=15; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  13.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  16.9s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=20; total time=  17.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  15.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  19.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  22.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5; total time=  20.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=15; total time=  18.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=15; total time=  16.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  30.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  34.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10; total time=  28.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  24.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=15; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=15; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=  22.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=  22.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=20; total time=  22.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  20.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20; total time=  23.6s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5; total time=  30.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=5; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=15; total time=  29.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5; total time=  28.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=15; total time=  25.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=5; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=15; total time=  24.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=15; total time=  28.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  28.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=15; total time=  26.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=2; total time=  25.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  25.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  41.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  42.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  43.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=  49.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 3.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 3.2min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 2.4min\n",
      "[CV] END ................................var_smoothing=1e-09; total time=   0.3s\n",
      "[CV] END ................................var_smoothing=1e-07; total time=   0.3s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   6.4s\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=   5.8s\n",
      "[CV] END .metric=minkowski, n_neighbors=20, weights=distance; total time=   6.2s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   6.6s\n",
      "[CV] END ..metric=euclidean, n_neighbors=20, weights=uniform; total time=   6.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time= 1.1min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time= 1.0min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  20.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  19.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  19.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  18.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  17.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2; total time=  15.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10; total time=  15.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20; total time=  15.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  13.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  13.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5; total time=  13.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  13.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2; total time=  12.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10; total time=  13.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  18.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  17.0s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  17.5s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  17.8s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  16.3s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  16.1s\n",
      "[CV] END criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  16.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  20.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2; total time=  22.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  19.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  17.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=10; total time=  16.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  16.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20; total time=  27.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  28.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=20; total time=  32.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5; total time=  31.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=15; total time=  27.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=5; total time=  24.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=15; total time=  24.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=  11.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5; total time=  11.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=15; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=  21.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=15; total time=  23.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2; total time=  22.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=15; total time=  22.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=5; total time=  21.4s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=15; total time=  21.0s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2; total time=  31.4s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10; total time=  29.5s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=2; total time=  27.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=2, min_samples_split=10; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2; total time=  29.2s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10; total time=  26.9s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20; total time=  26.3s\n",
      "[CV] END criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10; total time=  26.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  28.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  28.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=20; total time=  27.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  27.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=20; total time=  26.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=10; total time=  27.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=5, min_samples_split=20; total time=  26.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=5; total time=  25.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=10, min_samples_split=20; total time=  23.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=  43.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.1min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 3.1min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  49.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 3.1min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 3.1min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 1.6min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  44.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 3.2min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=  45.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 3.1min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50; total time=  42.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time= 1.4min\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50; total time=  40.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200; total time= 2.8min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 2.3min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time= 1.1min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 2.2min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  33.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 2.2min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50; total time=  34.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time= 1.1min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50; total time=  32.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time= 1.1min\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50; total time=  33.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100; total time= 1.1min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  49.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.6min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time= 1.6min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 3.4min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time= 1.7min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 3.0min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=50; total time=  43.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=2, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=50; total time=  44.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=5, n_estimators=100; total time= 1.5min\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=50; total time=  43.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=5, min_samples_split=10, n_estimators=200; total time= 3.0min\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 5.0min\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time= 1.1min\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 4.3min\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 4.3min\n",
      "Najlepsze parametry dla RF: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Najlepsza dokładność (CV) dla RF: 0.6468\n",
      "Model RF zapisany jako: ../models/dataset_1/RF_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.6234\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'NB',\n",
    "    'estimator': GaussianNB(),\n",
    "    'param_grid': {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:23:56.055030Z",
     "start_time": "2025-03-11T12:23:55.013613Z"
    }
   },
   "id": "3a68ca1cad615456",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: NB\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Najlepsze parametry dla NB: {'var_smoothing': 1e-09}\n",
      "Najlepsza dokładność (CV) dla NB: 0.6341\n",
      "Model NB zapisany jako: ../models/dataset_1/NB_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.5233\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'KNN',\n",
    "    'estimator': KNeighborsClassifier(),\n",
    "    'param_grid': {\n",
    "        'n_neighbors': [5, 10, 20],\n",
    "        'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:28:09.823121Z",
     "start_time": "2025-03-11T12:24:03.335645Z"
    }
   },
   "id": "14ee621b1eeb109b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: KNN\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Najlepsze parametry dla KNN: {'metric': 'manhattan', 'n_neighbors': 20, 'weights': 'uniform'}\n",
      "Najlepsza dokładność (CV) dla KNN: 0.3081\n",
      "Model KNN zapisany jako: ../models/dataset_1/KNN_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.3606\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'SVM',\n",
    "    'estimator': SVC(random_state=42),\n",
    "    'param_grid': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7f1ad5bc5a59d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "models_and_parameters = {\n",
    "    'model_name': 'MLP',\n",
    "        'estimator': MLPClassifier(random_state=42, early_stopping=True, n_iter_no_change=5),\n",
    "        'param_grid': {\n",
    "            'hidden_layer_sizes': [(100,), (50,50), (100,50,25)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate': ['constant', 'adaptive', 'invscaling']\n",
    "    }\n",
    "}\n",
    "\n",
    "model_name = models_and_parameters['model_name']\n",
    "\n",
    "print(f\"\\nPrzetwarzanie modelu: {model_name}\")\n",
    "estimator = models_and_parameters['estimator']\n",
    "param_grid = models_and_parameters['param_grid']\n",
    "\n",
    "grid = GridSearchCV(estimator, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Najlepsze parametry dla {model_name}: {grid.best_params_}\")\n",
    "print(f\"Najlepsza dokładność (CV) dla {model_name}: {grid.best_score_:.4f}\")\n",
    "\n",
    "model_filename = os.path.join('../models/dataset_1', f'{model_name}_best_model_d2v_dataset1.pkl')\n",
    "joblib.dump(grid.best_estimator_, model_filename)\n",
    "print(f\"Model {model_name} zapisany jako: {model_filename}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Dokładność na zbiorze testowym: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T19:49:57.401861Z",
     "start_time": "2025-03-11T19:08:41.469680Z"
    }
   },
   "id": "a6f9bde7fe43a754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Przetwarzanie modelu: MLP\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/weronika.najda/PycharmProjects/ml_dataset2/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla MLP: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50, 25), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Najlepsza dokładność (CV) dla MLP: 0.7584\n",
      "Model MLP zapisany jako: ../models/dataset_1/MLP_best_model_d2v_dataset1.pkl\n",
      "Dokładność na zbiorze testowym: 0.7210\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "ec9626ebff6c1657"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dataset2",
   "language": "python",
   "name": "ml_dataset2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
